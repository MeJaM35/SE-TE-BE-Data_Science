{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkNMasmyw9eL",
        "outputId": "314e09cc-8b6b-4e76-8054-42b3c91b00b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['campaign' 'election' 'football' 'goal' 'government' 'match' 'policy'\n",
            " 'politics' 'sports' 'team' 'win']\n",
            "Gini Index for 'goal': 0.0\n",
            "\n",
            "Information Gain for each feature:\n",
            "campaign: 0.09560258894703255\n",
            "election: 0.38039566584857787\n",
            "football: 0.09560258894703255\n",
            "goal: 0.38039566584857787\n",
            "government: 0.6931471805599452\n",
            "match: 0.21576155433883548\n",
            "policy: 0.21576155433883548\n",
            "politics: 0.21576155433883548\n",
            "sports: 0.21576155433883548\n",
            "team: 0.21576155433883548\n",
            "win: 0.21576155433883548\n",
            "\n",
            "Mutual Information for 'goal': 1.0\n",
            "\n",
            "Chi-Square (χ²) for each feature:\n",
            "campaign: 1.0\n",
            "election: 3.0\n",
            "football: 1.0\n",
            "goal: 3.0\n",
            "government: 4.0\n",
            "match: 2.0\n",
            "policy: 2.0\n",
            "politics: 2.0\n",
            "sports: 2.0\n",
            "team: 2.0\n",
            "win: 2.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import mutual_info_classif, chi2\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset\n",
        "documents = [\n",
        "    \"goal football win\",\n",
        "    \"goal match team\",\n",
        "    \"politics goal government election\",\n",
        "    \"government policy election\",\n",
        "    \"goal team sports\",\n",
        "    \"sports match win\",\n",
        "    \"government politics policy\",\n",
        "    \"election goal campaign government\",\n",
        "]\n",
        "\n",
        "# Labels: 1 = Sports, 0 = Politics\n",
        "labels = [1, 1, 0, 0, 1, 1, 0, 0]\n",
        "\n",
        "# Step 1: Bag-of-Words Representation\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents)  # Convert text to numeric matrix\n",
        "features = vectorizer.get_feature_names_out()  # Get feature names\n",
        "print(\"Features:\", features)\n",
        "\n",
        "# Step 2: Gini Index\n",
        "def gini_index(word_index, X, labels):\n",
        "    word_column = X[:, word_index].toarray().flatten()\n",
        "    total = len(labels)\n",
        "\n",
        "    # Probabilities for classes\n",
        "    p_class_1 = np.sum((word_column == 1) & (np.array(labels) == 1)) / np.sum(word_column)\n",
        "    p_class_0 = np.sum((word_column == 1) & (np.array(labels) == 0)) / np.sum(word_column)\n",
        "\n",
        "    gini = 1 - (p_class_1**2 + p_class_0**2)\n",
        "    return gini\n",
        "\n",
        "# Example: Gini Index for 'goal'\n",
        "gini_goal = gini_index(features.tolist().index(\"goal\"), X, labels)\n",
        "print(\"Gini Index for 'goal':\", gini_goal)\n",
        "\n",
        "# Step 3: Information Gain (Mutual Information)\n",
        "info_gain = mutual_info_classif(X, labels, discrete_features=True)\n",
        "print(\"\\nInformation Gain for each feature:\")\n",
        "for feature, ig in zip(features, info_gain):\n",
        "    print(f\"{feature}: {ig}\")\n",
        "\n",
        "# Step 4: Mutual Information (Specific to a class)\n",
        "def mutual_information(word_index, X, labels):\n",
        "    word_column = X[:, word_index].toarray().flatten()\n",
        "    total_docs = len(labels)\n",
        "\n",
        "    p_word = np.sum(word_column) / total_docs\n",
        "    p_class_1 = np.sum(labels) / total_docs\n",
        "    p_word_class_1 = np.sum((word_column == 1) & (np.array(labels) == 1)) / total_docs\n",
        "\n",
        "    mi = np.log2(p_word_class_1 / (p_word * p_class_1)) if p_word_class_1 > 0 else 0\n",
        "    return mi\n",
        "\n",
        "# Example: Mutual Information for 'goal'\n",
        "mi_goal = mutual_information(features.tolist().index(\"goal\"), X, labels)\n",
        "print(f\"\\nMutual Information for 'goal': {mi_goal}\")\n",
        "\n",
        "# Step 5: Chi-Square (χ²)\n",
        "chi2_values, p_values = chi2(X, labels)\n",
        "print(\"\\nChi-Square (χ²) for each feature:\")\n",
        "for feature, chi2_val in zip(features, chi2_values):\n",
        "    print(f\"{feature}: {chi2_val}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Insights:\n",
        "Features:\n",
        "\n",
        "The feature names correspond to the unique words found in the documents. For instance, goal, football, election, sports, and politics are all present in the dataset.\n",
        "Gini Index for 'goal':\n",
        "\n",
        "The Gini index for 'goal' is 0.0, which indicates that this feature does not provide much discrimination between the classes (Sports vs Politics) in this dataset. In this case, a Gini index of 0.0 means that the word 'goal' is perfectly classified (all the documents with the word 'goal' belong to a single class).\n",
        "Information Gain for Each Feature:\n",
        "\n",
        "The Information Gain values are used to measure how well each feature (word) can distinguish between the classes. Higher values mean the feature is more informative.\n",
        "For instance, the word government has the highest information gain (0.6931), indicating it is a strong feature for classification between the classes, whereas campaign, football, and goal have much lower values (~0.0956), suggesting they are less informative.\n",
        "Mutual Information for 'goal':\n",
        "\n",
        "The Mutual Information for the word 'goal' is 1.0, suggesting that there is a strong association between the word 'goal' and the class it is associated with. In this case, the strong positive mutual information indicates that knowing the word 'goal' almost guarantees knowledge of the class (Sports).\n",
        "Chi-Square (χ²) for Each Feature:\n",
        "\n",
        "The Chi-Square values represent how much the occurrence of a feature (word) deviates from what we would expect if the feature was independent of the class label.\n",
        "The word government has the highest χ² value (4.0), indicating that it has a stronger association with the class compared to other words with lower χ² values (2.0 for words like match, policy, sports, etc.).\n",
        "Interpretation:\n",
        "Gini Index (0.0 for 'goal'): This is a perfect indicator of class, meaning all occurrences of 'goal' belong to a single class. However, in many real cases, we'd expect higher Gini Index values for better discriminatory power.\n",
        "Information Gain: Words like government and election have the highest information gain, meaning they help the model classify more effectively between the two classes.\n",
        "Mutual Information: A high value for 'goal' suggests strong dependence with the class, implying it's a useful word for classification.\n",
        "Chi-Square: Words like government are significantly associated with specific classes, which is useful for classification purposes."
      ],
      "metadata": {
        "id": "r7LRWZZbyNvE"
      }
    }
  ]
}